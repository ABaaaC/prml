{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A fully probabilistic approach to PCA allows us to automatically choose the dimensionality of the principal subspace\n",
    "* In this notebook, we consider a model in which only $\\bf W$ has a prior distribution of the form\n",
    "\n",
    "$$\n",
    "    p({\\bf W}\\vert\\boldsymbol\\alpha) = \\prod_{m=1}^M \\left(\\frac{\\alpha_m}{2\\pi}\\right)^{D/2} \\exp\\left(-\\frac{\\alpha_m}{2}{\\bf w}_m^T{\\bf w}_m\\right)\n",
    "$$\n",
    "\n",
    "To choose the values of $\\{\\alpha_m\\}_{m=1}^M$, we maximize the marginal likelihood once $\\bf W$ has been integrated out. That is, we want to maximize \n",
    "\n",
    "$$\n",
    "    p({\\bf X}\\vert\\boldsymbol\\mu, \\boldsymbol\\mu, \\sigma^2) = \\int\\prod_{m=1}^M \\mathcal{N}({\\bf w}_m\\vert {\\bf 0}, \\alpha_m{\\bf I}) \\cdot \\mathcal{N}({\\bf x}_n \\vert \\boldsymbol\\mu,{\\bf C}) \\ \\text{d}{\\bf W} \\label{eq:a}\\tag{1}\n",
    "$$\n",
    "\n",
    "Where\n",
    "* ${\\bf C} = {\\bf W}{\\bf W}^T + \\sigma^2{\\bf I}$\n",
    "\n",
    "\n",
    "The integral over $\\eqref{eq:a}$ is intractable, thus we make use of the Laplace approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_iris, y_iris = iris[\"data\"], iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = X_iris.shape\n",
    "M = 2\n",
    "sigma2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.randn(D, M)\n",
    "S = np.cov(X_iris.T)\n",
    "C = W @ W.T + np.eye(D) * sigma2\n",
    "alpha = np.random.rand(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewriting the equation $\\sum_{m}\\alpha_m{\\bf w}^T_m{\\bf w}_m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5301657232594517"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum(\"m,jm,jm\",alpha, W, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.530165723259452"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(alpha * np.identity(M) @ W.T @ W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.20960248, 12.64040337],\n",
       "       [-2.29046053,  5.90228928],\n",
       "       [ 2.55310206, -6.50051632],\n",
       "       [-2.7095394 ,  1.46510875]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(S @ np.linalg.inv(C) - np.eye(D)) @ C @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3130791 , -1.96893035],\n",
       "       [ 0.55427098, -0.80387089],\n",
       "       [-1.00525531,  0.89190196],\n",
       "       [ 0.70597081, -0.14137084]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "1. https://papers.nips.cc/paper/1549-bayesian-pca.pdf\n",
    "2. https://www.cs.toronto.edu/~rsalakhu/STA4273_2015/notes/Lecture8_2015.pdf\n",
    "3. https://haralick.org/ML/Neural_Networks_for_Pattern_Recognition_Christopher_Bishop.pdf\n",
    "4. http://www.miketipping.com/papers/met-mppca.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
